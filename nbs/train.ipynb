{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubuntu environment only\n",
    "! apt install libasound2-dev portaudio19-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup AudioCraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/audiocraft.git\n",
    "%cd audiocraft\n",
    "!pip install -e .\n",
    "AUDIOCRAFT_ROOT = \"/content/audiocraft\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dora-search numba\n",
    "!pip install git+https://github.com/tnadav/prompt-synth.git#subdirectory=audiomanip\n",
    "!pip install torchvision==0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def make_dataset_yaml(\n",
    "    name: str, train_path: str, valid_path: str, eval_path: str, generate_path: str\n",
    ") -> None:\n",
    "    data = yaml.dump(\n",
    "        {\n",
    "            \"datasource\": {\n",
    "                \"max_channels\": 1,\n",
    "                \"max_sample_rate\": 32000,\n",
    "                \"evaluate\": eval_path,\n",
    "                \"generate\": generate_path,\n",
    "                \"train\": train_path,\n",
    "                \"valid\": valid_path,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    with open(f\"/content/audiocraft/config/dset/audio/{name}.yaml\", \"w\") as f:\n",
    "        _package = \"package\"\n",
    "        f.write(f\"# @{_package} __global__\\n\\n\")\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive/\")\n",
    "\n",
    "nsynth_train = \"/content/drive/MyDrive/prompt-synth/musicgen-nsynth-train-ext\"\n",
    "nsynth_valid = \"/content/drive/MyDrive/prompt-synth/musicgen-nsynth-valid-ext\"\n",
    "nsynth_test = \"/content/drive/MyDrive/prompt-synth/musicgen-nsynth-test-ext\"\n",
    "make_dataset_yaml(\n",
    "    \"nsynth-full-fixed-ext\",\n",
    "    train_path=nsynth_train,\n",
    "    valid_path=nsynth_valid,\n",
    "    eval_path=nsynth_test,\n",
    "    generate_path=nsynth_test,\n",
    ")\n",
    "\n",
    "!rm -rf /content/audiocraft/dataset/nsynth-test\n",
    "!cp -r /content/drive/MyDrive/prompt-synth/musicgen-nsynth-test/nsynth-test /content/audiocraft/dataset/nsynth-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NSynth samples to local dir\n",
    "import shutil\n",
    "\n",
    "shutil.copytree(nsynth_train, \"/content/audiocraft/dataset/nsynth-train-ext\")\n",
    "shutil.copytree(nsynth_valid, \"/content/audiocraft/dataset/nsynth-valid-ext\")\n",
    "shutil.copytree(nsynth_test, \"/content/audiocraft/dataset/nsynth-test-ext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using dora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env USER=nadav\n",
    "%env AUDIOCRAFT_TEAM=default\n",
    "\n",
    "# clear cuda mem\n",
    "from numba import cuda\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "\n",
    "command = (\n",
    "    \"dora run solver=magnet/magnet_32khz\"\n",
    "    \" model/lm/model_scale=small\"\n",
    "    \" continue_from=//pretrained/facebook/magnet-small-10secs\"\n",
    "    \" conditioner=text2music\"\n",
    "    \" dset=audio/nsynth-test\"\n",
    "    \" dataset.num_workers=1\"\n",
    "    \" dataset.valid.num_samples=1\"\n",
    "    \" dataset.batch_size=1\"  # batch_size 2 with T4 resulted in OOM\n",
    "    \" schedule.cosine.warmup=8\"\n",
    "    \" optim.optimizer=adamw\"  # uses dadaw by default, which is worse for single-gpu runs\n",
    "    \" optim.lr=1e-4\"\n",
    "    \" optim.epochs=5\"  # stops training after 5 epochs- change this\n",
    "    \" optim.updates_per_epoch=1000\"  # 2000 by default, change this if you want checkpoints quicker ig\n",
    "    \" optim.adam.weight_decay=0.01\"\n",
    ")\n",
    "\n",
    "!cd /content/audiocraft\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from audiocraft import train\n",
    "from audiocraft.utils import export\n",
    "\n",
    "def extract_xp_dataset_name(xp):\n",
    "    for arg in xp.argv:\n",
    "        if arg.startswith(\"dset=audio/\"):\n",
    "            return arg.replace(\"dset=audio/\", \"\")\n",
    "\n",
    "    raise ValueError(\"Couldn't extract dataset name\")\n",
    "\n",
    "def get_xp_name(xp):\n",
    "    train_name = extract_xp_dataset_name(xp)\n",
    "    return f\"{xp.cfg.solver}-{train_name}-{xp.cfg.optim.epochs}-epochs-{xp.sig}\"\n",
    "\n",
    "def export_model(sig, base_dir) -> str:\n",
    "    xp = train.main.get_xp_from_sig(sig)\n",
    "    name = get_xp_name(xp)\n",
    "    export_dir = os.path.join(base_dir, name)\n",
    "    os.makedirs(export_dir)\n",
    "\n",
    "    export.export_lm(\n",
    "        xp.folder / \"checkpoint.th\", os.path.join(export_dir, \"state_dict.bin\")\n",
    "    )\n",
    "    # Export pre-trained encoded. Modify if self trained encodec\n",
    "    export.export_pretrained_compression_model(\n",
    "        \"facebook/encodec_32khz\", os.path.join(export_dir, \"compression_state_dict.bin\")\n",
    "    )\n",
    "\n",
    "    return export_dir\n",
    "\n",
    "def list_xps():\n",
    "    for sig in os.listdir(\"/content/drive/MyDrive/prompt-synth/dora/xps\"):\n",
    "        try:\n",
    "            xp = train.main.get_xp_from_sig(sig)\n",
    "            print(f\"{sig}: {get_xp_name(xp)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {sig}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_xps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = \"d83d6943\"\n",
    "exported_model_dir = export_model(sig)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
